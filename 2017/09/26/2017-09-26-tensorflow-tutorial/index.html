<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/head/dragon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/head/dragon-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="TensorFlow官网上的指导的学习记录。">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow 笔记一">
<meta property="og:url" content="http://example.com/2017/09/26/2017-09-26-tensorflow-tutorial/index.html">
<meta property="og:site_name" content="龙">
<meta property="og:description" content="TensorFlow官网上的指导的学习记录。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2017-09-26T08:06:31.000Z">
<meta property="article:modified_time" content="2017-09-27T10:16:28.000Z">
<meta property="article:author" content="龙">
<meta property="article:tag" content="study">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2017/09/26/2017-09-26-tensorflow-tutorial/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>TensorFlow 笔记一 | 龙</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">龙</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">哇咔咔</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/09/26/2017-09-26-tensorflow-tutorial/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/head/head_bigfan.png">
      <meta itemprop="name" content="龙">
      <meta itemprop="description" content="哇咔咔">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="龙">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          TensorFlow 笔记一
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-09-26 16:06:31" itemprop="dateCreated datePublished" datetime="2017-09-26T16:06:31+08:00">2017-09-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2017-09-27 18:16:28" itemprop="dateModified" datetime="2017-09-27T18:16:28+08:00">2017-09-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/TensorFlow/" itemprop="url" rel="index"><span itemprop="name">TensorFlow</span></a>
                </span>
            </span>

          
            <div class="post-description">TensorFlow官网上的指导的学习记录。</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <hr>
<h2 id="Building-Input-Functions-with-tf-estimator"><a href="#Building-Input-Functions-with-tf-estimator" class="headerlink" title="Building Input Functions with tf.estimator"></a>Building Input Functions with tf.estimator</h2><p>直接从<code>Building Input Functions with tf.estimator</code>这一节开始，前面的就先不做笔记了。</p>
<h2 id=""><a href="#" class="headerlink" title=""></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">tf.logging.set_verbosity(tf.logging.INFO)</span><br><span class="line"></span><br><span class="line">COLUMNS = [<span class="string">&quot;crim&quot;</span>, <span class="string">&quot;zn&quot;</span>, <span class="string">&quot;indus&quot;</span>, <span class="string">&quot;nox&quot;</span>, <span class="string">&quot;rm&quot;</span>, <span class="string">&quot;age&quot;</span>,</span><br><span class="line">           <span class="string">&quot;dis&quot;</span>, <span class="string">&quot;tax&quot;</span>, <span class="string">&quot;ptratio&quot;</span>, <span class="string">&quot;medv&quot;</span>]</span><br><span class="line">FEATURES = [<span class="string">&quot;crim&quot;</span>, <span class="string">&quot;zn&quot;</span>, <span class="string">&quot;indus&quot;</span>, <span class="string">&quot;nox&quot;</span>, <span class="string">&quot;rm&quot;</span>,</span><br><span class="line">            <span class="string">&quot;age&quot;</span>, <span class="string">&quot;dis&quot;</span>, <span class="string">&quot;tax&quot;</span>, <span class="string">&quot;ptratio&quot;</span>]</span><br><span class="line">LABEL = <span class="string">&quot;medv&quot;</span></span><br><span class="line"></span><br><span class="line">training_set = pd.read_csv(<span class="string">&quot;boston_train.csv&quot;</span>, </span><br><span class="line">                           skipinitialspace=<span class="literal">True</span>, </span><br><span class="line">                           skiprows=<span class="number">1</span>, names=COLUMNS)</span><br><span class="line"></span><br><span class="line">test_set = pd.read_csv(<span class="string">&quot;boston_test.csv&quot;</span>, </span><br><span class="line">                       skipinitialspace=<span class="literal">True</span>, </span><br><span class="line">                       skiprows=<span class="number">1</span>, names=COLUMNS)</span><br><span class="line"></span><br><span class="line">prediction_set = pd.read_csv(<span class="string">&quot;boston_predict.csv&quot;</span>, </span><br><span class="line">                             skipinitialspace=<span class="literal">True</span>, </span><br><span class="line">                             skiprows=<span class="number">1</span>, names=COLUMNS)</span><br><span class="line"></span><br><span class="line">feature_cols = [tf.feature_column.numeric_column(k) <span class="keyword">for</span> k <span class="keyword">in</span> FEATURES]</span><br><span class="line"></span><br><span class="line">regressor = tf.estimator.DNNRegressor(feature_columns=feature_cols, </span><br><span class="line">                                      hidden_units=[<span class="number">10</span>, <span class="number">10</span>], model_dir=<span class="string">&quot;/tmp5/boston_model&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_input_fn</span>(<span class="params">data_set, num_epochs=<span class="literal">None</span>, shuffle=<span class="literal">True</span></span>):</span></span><br><span class="line">  <span class="keyword">return</span> tf.estimator.inputs.pandas_input_fn(</span><br><span class="line">      x=pd.DataFrame(&#123;k: data_set[k].values <span class="keyword">for</span> k <span class="keyword">in</span> FEATURES&#125;),</span><br><span class="line">      y = pd.Series(data_set[LABEL].values),</span><br><span class="line">      num_epochs=num_epochs,</span><br><span class="line">      shuffle=shuffle)</span><br><span class="line"></span><br><span class="line">regressor.train(input_fn=get_input_fn(training_set), steps=<span class="number">5000</span>)</span><br><span class="line"></span><br><span class="line">ev = regressor.evaluate(input_fn=get_input_fn(test_set, num_epochs=<span class="number">1</span>, shuffle=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">loss_score = ev[<span class="string">&quot;loss&quot;</span>]</span><br><span class="line">print(<span class="string">&quot;Loss: &#123;0:f&#125;&quot;</span>.<span class="built_in">format</span>(loss_score))</span><br><span class="line"></span><br><span class="line">y = regressor.predict(</span><br><span class="line">    input_fn=get_input_fn(prediction_set, num_epochs=<span class="number">1</span>, shuffle=<span class="literal">False</span>))</span><br><span class="line">    </span><br><span class="line"><span class="comment"># .predict() returns an iterator of dicts; convert to a list and print predictions</span></span><br><span class="line">predictions = <span class="built_in">list</span>(p[<span class="string">&quot;predictions&quot;</span>] <span class="keyword">for</span> p <span class="keyword">in</span> itertools.islice(y, <span class="number">6</span>))</span><br><span class="line">print(<span class="string">&quot;Predictions: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(predictions)))</span><br></pre></td></tr></table></figure></h2><p><strong>一段一段的理解：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br></pre></td></tr></table></figure>
<p>这里从<code>__future__</code>这个包下引入了<code>absolute_import</code>，<code>division</code>，<code>print_function</code>。</p>
<p>首先看<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/__future__.html?highlight=future#module-__future__"><strong>future</strong>官方API</a>，
简单来说就是将python的后面版本新特性导入到当前版本，使得当然版本也可以使用后面版本的语法。</p>
<p>看文档最后的表就知道，这里我使用的python3.6.1，所以这里的代码可以不写，如果是python较低版本，比如2.xxx，那就能需要导入一下了。</p>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"></span><br><span class="line">predictions = <span class="built_in">list</span>(p[<span class="string">&quot;predictions&quot;</span>] <span class="keyword">for</span> p <span class="keyword">in</span> itertools.islice(y, <span class="number">6</span>))</span><br></pre></td></tr></table></figure>
<p>同样的，来查看<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/itertools.html?highlight=itertools">itertools官方API</a>，
它是一个迭代的工具类，提供了各种迭代的方法。</p>
<p>这里的，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">itertools.islice(y, <span class="number">6</span>)</span><br></pre></td></tr></table></figure>
<p>创建了一个迭代器，从<code>y</code>集合的第<strong>1</strong>个元素开始到第<strong>6</strong>个元素结束。</p>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<p>一样的<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/10min.html">官方10 Minutes to pandas</a>，
<strong>pandas</strong>是基于<code>numpy</code>的，在做数据分析时，用它来表示矩阵向量可能更加方便快捷。</p>
<p>在安装<strong>pandas</strong>时，直接使用<code>pip3 install pandas</code>会很慢，基本等于失败，换源后效果显著，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple some-package</span><br></pre></td></tr></table></figure>
<p>这里换成清华源来安装，速度很快。</p>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.logging.set_verbosity(tf.logging.INFO)</span><br></pre></td></tr></table></figure>
<p>打开这个过后，在进行训练时，会打印很多中间过程的信息，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">INFO:tensorflow:Restoring parameters from &#x2F;tmp5&#x2F;boston_model\model.ckpt-15000</span><br><span class="line">INFO:tensorflow:Saving checkpoints for 15001 into &#x2F;tmp5&#x2F;boston_model\model.ckpt.</span><br><span class="line">INFO:tensorflow:loss &#x3D; 1842.78, step &#x3D; 15001</span><br><span class="line">INFO:tensorflow:global_step&#x2F;sec: 702.316</span><br><span class="line">INFO:tensorflow:loss &#x3D; 3675.04, step &#x3D; 15101 (0.143 sec)</span><br><span class="line">INFO:tensorflow:global_step&#x2F;sec: 779.157</span><br><span class="line">INFO:tensorflow:loss &#x3D; 2918.1, step &#x3D; 15201 (0.128 sec)</span><br><span class="line">INFO:tensorflow:global_step&#x2F;sec: 667.102</span><br><span class="line">INFO:tensorflow:loss &#x3D; 4292.76, step &#x3D; 15301 (0.150 sec)</span><br><span class="line">INFO:tensorflow:global_step&#x2F;sec: 704.81</span><br><span class="line">INFO:tensorflow:loss &#x3D; 2817.55, step &#x3D; 15401 (0.142 sec)</span><br><span class="line">INFO:tensorflow:global_step&#x2F;sec: 727.968</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>这里每<strong>100</strong>次迭代打印一次当前损失。</p>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">COLUMNS = [<span class="string">&quot;crim&quot;</span>, <span class="string">&quot;zn&quot;</span>, <span class="string">&quot;indus&quot;</span>, <span class="string">&quot;nox&quot;</span>, <span class="string">&quot;rm&quot;</span>, <span class="string">&quot;age&quot;</span>,</span><br><span class="line">           <span class="string">&quot;dis&quot;</span>, <span class="string">&quot;tax&quot;</span>, <span class="string">&quot;ptratio&quot;</span>, <span class="string">&quot;medv&quot;</span>]</span><br><span class="line">FEATURES = [<span class="string">&quot;crim&quot;</span>, <span class="string">&quot;zn&quot;</span>, <span class="string">&quot;indus&quot;</span>, <span class="string">&quot;nox&quot;</span>, <span class="string">&quot;rm&quot;</span>,</span><br><span class="line">            <span class="string">&quot;age&quot;</span>, <span class="string">&quot;dis&quot;</span>, <span class="string">&quot;tax&quot;</span>, <span class="string">&quot;ptratio&quot;</span>]</span><br><span class="line">LABEL = <span class="string">&quot;medv&quot;</span></span><br></pre></td></tr></table></figure>
<p>定义三个list，第一个是读文件时需要读取的列，第二个是样本的属性，第三个是标签列。定义这个方便对属性和标签进行拆分。</p>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">regressor = tf.estimator.DNNRegressor(feature_columns=feature_cols, </span><br><span class="line">                                      hidden_units=[<span class="number">10</span>, <span class="number">10</span>], model_dir=<span class="string">&quot;/tmp5/boston_model&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>定义了一个深度学习回归模型，<code>[10, 10]</code>指定了模型共两层，每层<strong>10</strong>个神经元，<code>model_dir=&quot;/tmp5/boston_model&quot;</code>表示了模型存储的位置。</p>
<p><strong>注意</strong>，这里的<code>/tmp5/boston_model</code>在<strong>windows</strong>下面表示是在根目录下的<code>tmp5</code>文件夹，比如程序是在<code>F盘</code>下执行的，
那么它建立一个<code>F:/tmp5/</code>目录，如果需要当前目录下的<code>tmp5</code>目录，那就要使用<code>tmp5/boston_model</code>路径。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">feature_cols &#x3D; [tf.feature_column.numeric_column(k) for k in FEATURES]</span><br></pre></td></tr></table></figure>
<p>这里先将<strong>FEATURES</strong>转化成回归模型所需的格式，然后传入模型。</p>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_input_fn</span>(<span class="params">data_set, num_epochs=<span class="literal">None</span>, shuffle=<span class="literal">True</span></span>):</span></span><br><span class="line">  <span class="keyword">return</span> tf.estimator.inputs.pandas_input_fn(</span><br><span class="line">      x=pd.DataFrame(&#123;k: data_set[k].values <span class="keyword">for</span> k <span class="keyword">in</span> FEATURES&#125;),</span><br><span class="line">      y = pd.Series(data_set[LABEL].values),</span><br><span class="line">      num_epochs=num_epochs,</span><br><span class="line">      shuffle=shuffle)</span><br><span class="line"></span><br><span class="line">regressor.train(input_fn=get_input_fn(training_set), steps=<span class="number">5000</span>)</span><br></pre></td></tr></table></figure>
<p>注意这里<code>get_input_fn</code>中调用的<code>tf.estimator.inputs.pandas_input_fn(...)</code>返回的是一个函数，因为<code>train()</code>里面接受的是一个函数对象。</p>
<p>这里调用时按照格式来的，<code>num_epochs</code>代表数据集可以过几遍，对训练集当然没有限制，所以输入数<code>None</code>，对于验证集或者测试集，
这里的<code>num_epochs</code>就要设置为<strong>1</strong>，因为一个样本只需要过一次，同样的，<code>shuffle</code>表示是否随机读取样本，也只有训练集需要随机读取操作。</p>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ev = regressor.evaluate(input_fn=get_input_fn(test_set, num_epochs=<span class="number">1</span>, shuffle=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">loss_score = ev[<span class="string">&quot;loss&quot;</span>]</span><br><span class="line">print(<span class="string">&quot;Loss: &#123;0:f&#125;&quot;</span>.<span class="built_in">format</span>(loss_score))</span><br></pre></td></tr></table></figure>
<p>训练完成后，使用验证集进行验证，这里打印出损失分数。</p>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y = regressor.predict(</span><br><span class="line">    input_fn=get_input_fn(prediction_set, num_epochs=<span class="number">1</span>, shuffle=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># .predict() returns an iterator of dicts; convert to a list and print predictions</span></span><br><span class="line">predictions = <span class="built_in">list</span>(p[<span class="string">&quot;predictions&quot;</span>] <span class="keyword">for</span> p <span class="keyword">in</span> itertools.islice(y, <span class="number">6</span>))</span><br><span class="line">print(<span class="string">&quot;Predictions: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(predictions)))</span><br></pre></td></tr></table></figure>
<p>这里就是测试预测的结果，想要的效果是，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Predictions: [33.480186, 18.6161, 23.09123, 34.338253, 16.050083, 19.354153]</span><br></pre></td></tr></table></figure>
<p>实际的结果是，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Predictions: [array([ 33.83599091], dtype&#x3D;float32), array([ 17.83500481], dtype&#x3D;float32),</span><br><span class="line"> array([ 24.12747383], dtype&#x3D;float32), array([ 35.41732025], dtype&#x3D;float32), </span><br><span class="line"> array([ 15.54900551], dtype&#x3D;float32), array([ 17.97283173], dtype&#x3D;float32)]</span><br></pre></td></tr></table></figure>
<p>说明这里<code>predict()</code>返回的是一个列表，但是列表中的元素是<code>array</code>对象，所以这里要简单改动一下，</p>
<h2 id="-1"><a href="#-1" class="headerlink" title=""></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predictions = <span class="built_in">list</span>(p[<span class="string">&quot;predictions&quot;</span>][<span class="number">0</span>] <span class="keyword">for</span> p <span class="keyword">in</span> itertools.islice(y, <span class="number">6</span>))</span><br></pre></td></tr></table></figure></h2><hr>
<h2 id="TensorBoard-Visualizing-Learning"><a href="#TensorBoard-Visualizing-Learning" class="headerlink" title="TensorBoard: Visualizing Learning"></a>TensorBoard: Visualizing Learning</h2><p>同样的，直接阅读代码，来看看整个流程到底发生了什么，<a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py">mnist_with_summaries.py</a>。</p>
<hr>
<p>首先，看<strong>入口</strong>函数:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">  </span><br><span class="line">  parser = argparse.ArgumentParser()</span><br><span class="line">  parser.add_argument(<span class="string">&#x27;--fake_data&#x27;</span>, nargs=<span class="string">&#x27;?&#x27;</span>, const=<span class="literal">True</span>, <span class="built_in">type</span>=<span class="built_in">bool</span>,</span><br><span class="line">                      default=<span class="literal">False</span>,</span><br><span class="line">                      <span class="built_in">help</span>=<span class="string">&#x27;If true, uses fake data for unit testing.&#x27;</span>)</span><br><span class="line">  parser.add_argument(<span class="string">&#x27;--max_steps&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1000</span>,</span><br><span class="line">                      <span class="built_in">help</span>=<span class="string">&#x27;Number of steps to run trainer.&#x27;</span>)</span><br><span class="line">  parser.add_argument(<span class="string">&#x27;--learning_rate&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.001</span>,</span><br><span class="line">                      <span class="built_in">help</span>=<span class="string">&#x27;Initial learning rate&#x27;</span>)</span><br><span class="line">  parser.add_argument(<span class="string">&#x27;--dropout&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.9</span>,</span><br><span class="line">                      <span class="built_in">help</span>=<span class="string">&#x27;Keep probability for training dropout.&#x27;</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">&#x27;--data_dir&#x27;</span>,</span><br><span class="line">      <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">      default=os.path.join(os.getenv(<span class="string">&#x27;TEST_TMPDIR&#x27;</span>, <span class="string">&#x27;/tmp&#x27;</span>),</span><br><span class="line">                           <span class="string">&#x27;tensorflow/mnist/input_data&#x27;</span>),</span><br><span class="line">      <span class="built_in">help</span>=<span class="string">&#x27;Directory for storing input data&#x27;</span>)</span><br><span class="line">  parser.add_argument(</span><br><span class="line">      <span class="string">&#x27;--log_dir&#x27;</span>,</span><br><span class="line">      <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">      default=os.path.join(os.getenv(<span class="string">&#x27;TEST_TMPDIR&#x27;</span>, <span class="string">&#x27;/tmp&#x27;</span>),</span><br><span class="line">                           <span class="string">&#x27;tensorflow/mnist/logs/mnist_with_summaries&#x27;</span>),</span><br><span class="line">      <span class="built_in">help</span>=<span class="string">&#x27;Summaries log directory&#x27;</span>)</span><br><span class="line">  FLAGS, unparsed = parser.parse_known_args()</span><br><span class="line">  tf.app.run(main=main, argv=[sys.argv[<span class="number">0</span>]] + unparsed)</span><br></pre></td></tr></table></figure>
<p>第一句，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br></pre></td></tr></table></figure>
<p>表示下面的代码只有在这个文件被当做脚本执行时才会执行。</p>
<p>下一句，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--fake_data&#x27;</span>, nargs=<span class="string">&#x27;?&#x27;</span>, const=<span class="literal">True</span>, <span class="built_in">type</span>=<span class="built_in">bool</span>,</span><br><span class="line">                    default=<span class="literal">False</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;If true, uses fake data for unit testing.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>参考<a target="_blank" rel="noopener" href="http://longrm.com/2017/09/26/2017-09-26-python-argparse/">argparse笔记</a>来理解，
那么这里也就是定义了输入的可选参数，同时也设定了默认值。</p>
<p>然后关注这一句，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">default=os.path.join( os.getenv(<span class="string">&#x27;TEST_TMPDIR&#x27;</span>, <span class="string">&#x27;/tmp&#x27;</span>),</span><br><span class="line">                      <span class="string">&#x27;tensorflow/mnist/input_data&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>其中<code>os.getenv(&#39;TEST_TMPDIR&#39;, &#39;/tmp&#39;)</code>是查询系统信息的函数，它去查询系统中<code>&#39;TEST_TMPDIR&#39;</code>的值，
显然这里没有对<code>&#39;TEST_TMPDIR&#39;</code>定义，于是它就会返回这里的设置默认值<code>&#39;/tmp&#39;</code>，否则返回<code>null</code>。</p>
<p>然后，对于<code>os.path.join()</code>它就是一个将路径合并的函数，例如，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ os.path.join(<span class="string">&#x27;/hello/&#x27;</span>,<span class="string">&#x27;good/boy/&#x27;</span>,<span class="string">&#x27;doiido&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;/hello/good/boy/doiido&#x27;</span></span><br></pre></td></tr></table></figure>
<p>但是如果是在windows下面执行，它就会变成下面这样，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ os.path.join( <span class="string">&#x27;/tmp&#x27;</span>, <span class="string">&#x27;tensorflow/mnist/input_data&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;/tmp\\tensorflow/mnist/input_data&#x27;</span></span><br></pre></td></tr></table></figure>
<p>我去，所以在windows下面执行的时候老是路径报错。</p>
<p>接着就是<code>main</code>函数的最后两句，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FLAGS, unparsed = parser.parse_known_args()</span><br><span class="line">tf.app.run(main=main, argv=[sys.argv[<span class="number">0</span>]] + unparsed)</span><br></pre></td></tr></table></figure>
<p>随便百度就可以看到它的源代码，它所进行的操作就是传入<code>main</code>函数，然后再传入参数，然后运行。
这里<code>FLAGS</code>里面的参数我们已经使用了，所以将剩下的参数传入，其中<code>sys.argv[0]</code>是当前文件的路径位置，
<code>unparsed</code>就是剩下未使用的参数。</p>
<hr>
<p>其次看<strong>main</strong>函数，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">_</span>):</span></span><br><span class="line">  <span class="keyword">if</span> tf.gfile.Exists(FLAGS.log_dir):</span><br><span class="line">    tf.gfile.DeleteRecursively(FLAGS.log_dir)</span><br><span class="line">  tf.gfile.MakeDirs(FLAGS.log_dir)</span><br><span class="line">  train()</span><br></pre></td></tr></table></figure>
<p>这里的<code>log_dir</code>就是日志文件，也就是<strong>TensorBoard</strong>画图时所需要的文件。
操作就是删除旧的日志文件，然后重新建一个文件夹，再调用<strong>train()</strong>函数。</p>
<hr>
<p><strong>这里来到train()函数，剩下的所有代码都在这里面。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(FLAGS.data_dir,</span><br><span class="line">                                  one_hot=<span class="literal">True</span>,</span><br><span class="line">                                  fake_data=FLAGS.fake_data)</span><br></pre></td></tr></table></figure>
<p>这个部分会读取本地的<code>mnist</code>数据集，如果没有它就会先将数据集下载下来，放到指定的数据目录里面。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.InteractiveSession()</span><br></pre></td></tr></table></figure>
<p>这一句使用了<strong>InteractiveSession()</strong>来建立了会话，它与<strong>Session()</strong>的不同之处在于，使用了它之后，
调用时<strong>run()</strong>变成了<strong>tf.global_variables_initializer().run()</strong>。</p>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Input placeholders</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;input&#x27;</span>):</span><br><span class="line">  x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>], name=<span class="string">&#x27;x-input&#x27;</span>)</span><br><span class="line">  y_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>], name=<span class="string">&#x27;y-input&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这里定义了两个输入的占位符。使用<strong>name_scope()</strong>使得在TensorBoard上它们会同处于<code>&#39;input&#39;</code>这个命名之下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;input_reshape&#x27;</span>):</span><br><span class="line">  image_shaped_input = tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line">  tf.summary.image(<span class="string">&#x27;input&#x27;</span>, image_shaped_input, <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>这里将输入重新<strong>reshape</strong>变成方阵（图片本来的形式），然后使用<code>tf.summary.image()</code>将它记录到日志里。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># We can&#x27;t initialize these variables to 0 - the network will get stuck.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span>(<span class="params">shape</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;Create a weight variable with appropriate initialization.&quot;&quot;&quot;</span></span><br><span class="line">  initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</span><br><span class="line">  <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span>(<span class="params">shape</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;Create a bias variable with appropriate initialization.&quot;&quot;&quot;</span></span><br><span class="line">  initial = tf.constant(<span class="number">0.1</span>, shape=shape)</span><br><span class="line">  <span class="keyword">return</span> tf.Variable(initial)</span><br></pre></td></tr></table></figure>
<p>定义了一个权重初始化的函数，输入需要初始化权重的<code>shape</code>，然后第一句进行了一个<code>truncated_normal()</code>，
它进行正态初始化，但是对于超出正态一定范围的值进行丢弃，返回的是一个<code>tensor</code>。
然后使用<code>tf.Variable()</code>将它变成一个变量。</p>
<p>同样的，将<code>bias</code>初始为<strong>0.1</strong>。</p>
<hr>
<p>下面的函数是专门用来对变量进行记录的，提供给<code>TensorBoard</code>去使用，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">variable_summaries</span>(<span class="params">var</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Attach a lot of summaries to a Tensor (for TensorBoard visualization).&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;summaries&#x27;</span>):</span><br><span class="line">        mean = tf.reduce_mean(var)</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;mean&#x27;</span>, mean)</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;stddev&#x27;</span>):</span><br><span class="line">            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;stddev&#x27;</span>, stddev)</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;max&#x27;</span>, tf.reduce_max(var))</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;min&#x27;</span>, tf.reduce_min(var))</span><br><span class="line">        tf.summary.histogram(<span class="string">&#x27;histogram&#x27;</span>, var)</span><br></pre></td></tr></table></figure>
<p>记录下变量的均值，标准差，最大值，最小值，柱状图。</p>
<p>接着的一个函数用来构建神经网络层，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nn_layer</span>(<span class="params">input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Reusable code for making a simple neural net layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    It does a matrix multiply, bias add, and then uses ReLU to nonlinearize.</span></span><br><span class="line"><span class="string">    It also sets up name scoping so that the resultant graph is easy to read,</span></span><br><span class="line"><span class="string">    and adds a number of summary ops.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Adding a name scope ensures logical grouping of the layers in the graph.</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(layer_name):</span><br><span class="line">      <span class="comment"># This Variable will hold the state of the weights for the layer</span></span><br><span class="line">      <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;weights&#x27;</span>):</span><br><span class="line">        weights = weight_variable([input_dim, output_dim])</span><br><span class="line">        variable_summaries(weights)</span><br><span class="line">      <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;biases&#x27;</span>):</span><br><span class="line">        biases = bias_variable([output_dim])</span><br><span class="line">        variable_summaries(biases)</span><br><span class="line">      <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;Wx_plus_b&#x27;</span>):</span><br><span class="line">        preactivate = tf.matmul(input_tensor, weights) + biases</span><br><span class="line">        tf.summary.histogram(<span class="string">&#x27;pre_activations&#x27;</span>, preactivate)</span><br><span class="line">      activations = act(preactivate, name=<span class="string">&#x27;activation&#x27;</span>)</span><br><span class="line">      tf.summary.histogram(<span class="string">&#x27;activations&#x27;</span>, activations)</span><br><span class="line">      <span class="keyword">return</span> activations</span><br></pre></td></tr></table></figure>
<p>初始化权重并记录，初始化偏置并记录。计算通过激活函数前的输出并记录，计算输出并记录，最后返回输出。</p>
<hr>
<p><strong>下面开始构建神经网络，</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hidden1 = nn_layer(x, <span class="number">784</span>, <span class="number">500</span>, <span class="string">&#x27;layer1&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>首先构建了第一层隐藏层，神经元数量500。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;dropout&#x27;</span>):</span><br><span class="line">  keep_prob = tf.placeholder(tf.float32)</span><br><span class="line">  tf.summary.scalar(<span class="string">&#x27;dropout_keep_probability&#x27;</span>, keep_prob)</span><br><span class="line">  dropped = tf.nn.dropout(hidden1, keep_prob)</span><br></pre></td></tr></table></figure>
<p>下一步则是在第一层之后，加入了一个<code>dropout</code>层，这里的<code>keep_prob</code>使用了占位符，以便调整。同样也将概率进行记录。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Do not apply softmax activation yet, see below.</span></span><br><span class="line">y = nn_layer(dropped, <span class="number">500</span>, <span class="number">10</span>, <span class="string">&#x27;layer2&#x27;</span>, act=tf.identity)</span><br></pre></td></tr></table></figure>
<p>这里建立了神经网络的第二层，但是激活函数这里传入的是一个<code>tf.identity</code>，这个函数的意思是，
传入什么数，它就传出什么数…那么这里就相当于是没有激活函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;cross_entropy&#x27;</span>):</span><br><span class="line">  <span class="comment"># The raw formulation of cross-entropy,</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.softmax(y)),</span></span><br><span class="line">  <span class="comment">#                               reduction_indices=[1]))</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># can be numerically unstable.</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># So here we use tf.nn.softmax_cross_entropy_with_logits on the</span></span><br><span class="line">  <span class="comment"># raw outputs of the nn_layer above, and then average across</span></span><br><span class="line">  <span class="comment"># the batch.</span></span><br><span class="line">  diff = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)</span><br><span class="line">  <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;total&#x27;</span>):</span><br><span class="line">    cross_entropy = tf.reduce_mean(diff)</span><br><span class="line">tf.summary.scalar(<span class="string">&#x27;cross_entropy&#x27;</span>, cross_entropy)</span><br></pre></td></tr></table></figure>
<p>这里就像它注释里面写的，它先计算了整体的交叉熵，然后取了一下均值，最后进行记录。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;train&#x27;</span>):</span><br><span class="line">  train_step = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(</span><br><span class="line">        cross_entropy)</span><br></pre></td></tr></table></figure>
<p>调用<code>AdamOptimizer()</code>来进行优化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;accuracy&#x27;</span>):</span><br><span class="line">  <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;correct_prediction&#x27;</span>):</span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">  <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;accuracy&#x27;</span>):</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">tf.summary.scalar(<span class="string">&#x27;accuracy&#x27;</span>, accuracy)</span><br></pre></td></tr></table></figure>
<p>首先，这里的<strong>y</strong>是一个行向量，所以使用<code>tf.argmax(y, 1)</code>将它每一行的最大值得下标找出来。同时，
<code>tf.equal()</code>将返回一个<code>bool</code>值组成的<code>tensor</code>。</p>
<p>使用<code>tf.reduce_mean()</code>计算一下均值，就得到了当前的准确率，然后将它进行记录。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Merge all the summaries and write them out to</span></span><br><span class="line"><span class="comment"># /tmp/tensorflow/mnist/logs/mnist_with_summaries (by default)</span></span><br><span class="line">merged = tf.summary.merge_all()</span><br><span class="line">train_writer = tf.summary.FileWriter(FLAGS.log_dir + <span class="string">&#x27;/train&#x27;</span>, sess.graph)</span><br><span class="line">test_writer = tf.summary.FileWriter(FLAGS.log_dir + <span class="string">&#x27;/test&#x27;</span>)</span><br><span class="line">tf.global_variables_initializer().run()</span><br></pre></td></tr></table></figure>
<p>将所有的日志合并，进行共同的操作。然后定义日志写入的位置。最后将变量初始化。</p>
<hr>
<p>最后就到了训练阶段，首先定义了<code>feed_dict</code>函数，用来给占位符赋值，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feed_dict</span>(<span class="params">train</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;Make a TensorFlow feed_dict: maps data onto Tensor placeholders.&quot;&quot;&quot;</span></span><br><span class="line">  <span class="keyword">if</span> train <span class="keyword">or</span> FLAGS.fake_data:</span><br><span class="line">    xs, ys = mnist.train.next_batch(<span class="number">100</span>, fake_data=FLAGS.fake_data)</span><br><span class="line">    k = FLAGS.dropout</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    xs, ys = mnist.test.images, mnist.test.labels</span><br><span class="line">    k = <span class="number">1.0</span></span><br><span class="line">  <span class="keyword">return</span> &#123;x: xs, y_: ys, keep_prob: k&#125;</span><br></pre></td></tr></table></figure>
<p>如果是训练阶段，那么就<code>mnist.train</code>中取出一个<code>batch</code>给<code>x</code>和<code>y</code>，如果不是训练阶段，
在这里肯定就是测试阶段了，那么就把整个测试集传给<code>x</code>和<code>y</code>。</p>
<p>下面就是训练代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train the model, and also write summaries.</span></span><br><span class="line"><span class="comment"># Every 10th step, measure test-set accuracy, and write test summaries</span></span><br><span class="line"><span class="comment"># All other steps, run train_step on training data, &amp; add training summaries </span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(FLAGS.max_steps):</span><br><span class="line">  <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:  <span class="comment"># Record summaries and test-set accuracy</span></span><br><span class="line">    summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(<span class="literal">False</span>))</span><br><span class="line">    test_writer.add_summary(summary, i)</span><br><span class="line">    print(<span class="string">&#x27;Accuracy at step %s: %s&#x27;</span> % (i, acc))</span><br><span class="line">  <span class="keyword">else</span>:  <span class="comment"># Record train set summaries, and train</span></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">99</span>:  <span class="comment"># Record execution stats</span></span><br><span class="line">      run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)</span><br><span class="line">      run_metadata = tf.RunMetadata()</span><br><span class="line">      summary, _ = sess.run([merged, train_step],</span><br><span class="line">                            feed_dict=feed_dict(<span class="literal">True</span>),</span><br><span class="line">                            options=run_options,</span><br><span class="line">                            run_metadata=run_metadata)</span><br><span class="line">      train_writer.add_run_metadata(run_metadata, <span class="string">&#x27;step%03d&#x27;</span> % i)</span><br><span class="line">      train_writer.add_summary(summary, i)</span><br><span class="line">      print(<span class="string">&#x27;Adding run metadata for&#x27;</span>, i)</span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># Record a summary</span></span><br><span class="line">      summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(<span class="literal">True</span>))</span><br><span class="line">      train_writer.add_summary(summary, i)</span><br><span class="line">train_writer.close()</span><br><span class="line">test_writer.close()</span><br></pre></td></tr></table></figure>
<p>首先，每运行<strong>10</strong>步，就计算一下当前的准确度，并将日志数据写入<strong>test</strong>日志文件。</p>
<p>然后，每隔<strong>100</strong>步，加入<code>tf.RunOptions()</code>和<code>tf.RunMetadata()</code>，这好像是一些原信息，类似运行时间什么的。</p>
<p>剩下的步骤就是正常的训练，每次训练的日志都写入<code>train</code>日志文件。</p>
<p>最后关闭<code>train_writer</code>和<code>test_writer</code>。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/study/" rel="tag"># study</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2017/09/18/2017-09-18-anaconda/" rel="prev" title="Anaconda 使用记录">
      <i class="fa fa-chevron-left"></i> Anaconda 使用记录
    </a></div>
      <div class="post-nav-item">
    <a href="/2017/09/26/2017-09-26-python-argparse/" rel="next" title="python argparse 模块笔记">
      python argparse 模块笔记 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Building-Input-Functions-with-tf-estimator"><span class="nav-number">1.</span> <span class="nav-text">Building Input Functions with tf.estimator</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">2.</span> <span class="nav-text">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import itertools

import pandas as pd
import tensorflow as tf

tf.logging.set_verbosity(tf.logging.INFO)

COLUMNS &#x3D; [&quot;crim&quot;, &quot;zn&quot;, &quot;indus&quot;, &quot;nox&quot;, &quot;rm&quot;, &quot;age&quot;,
           &quot;dis&quot;, &quot;tax&quot;, &quot;ptratio&quot;, &quot;medv&quot;]
FEATURES &#x3D; [&quot;crim&quot;, &quot;zn&quot;, &quot;indus&quot;, &quot;nox&quot;, &quot;rm&quot;,
            &quot;age&quot;, &quot;dis&quot;, &quot;tax&quot;, &quot;ptratio&quot;]
LABEL &#x3D; &quot;medv&quot;

training_set &#x3D; pd.read_csv(&quot;boston_train.csv&quot;, 
                           skipinitialspace&#x3D;True, 
                           skiprows&#x3D;1, names&#x3D;COLUMNS)

test_set &#x3D; pd.read_csv(&quot;boston_test.csv&quot;, 
                       skipinitialspace&#x3D;True, 
                       skiprows&#x3D;1, names&#x3D;COLUMNS)

prediction_set &#x3D; pd.read_csv(&quot;boston_predict.csv&quot;, 
                             skipinitialspace&#x3D;True, 
                             skiprows&#x3D;1, names&#x3D;COLUMNS)

feature_cols &#x3D; [tf.feature_column.numeric_column(k) for k in FEATURES]

regressor &#x3D; tf.estimator.DNNRegressor(feature_columns&#x3D;feature_cols, 
                                      hidden_units&#x3D;[10, 10], model_dir&#x3D;&quot;&#x2F;tmp5&#x2F;boston_model&quot;)

def get_input_fn(data_set, num_epochs&#x3D;None, shuffle&#x3D;True):
  return tf.estimator.inputs.pandas_input_fn(
      x&#x3D;pd.DataFrame(&amp;#123;k: data_set[k].values for k in FEATURES&amp;#125;),
      y &#x3D; pd.Series(data_set[LABEL].values),
      num_epochs&#x3D;num_epochs,
      shuffle&#x3D;shuffle)

regressor.train(input_fn&#x3D;get_input_fn(training_set), steps&#x3D;5000)

ev &#x3D; regressor.evaluate(input_fn&#x3D;get_input_fn(test_set, num_epochs&#x3D;1, shuffle&#x3D;False))

loss_score &#x3D; ev[&quot;loss&quot;]
print(&quot;Loss: &amp;#123;0:f&amp;#125;&quot;.format(loss_score))

y &#x3D; regressor.predict(
    input_fn&#x3D;get_input_fn(prediction_set, num_epochs&#x3D;1, shuffle&#x3D;False))
    
# .predict() returns an iterator of dicts; convert to a list and print predictions
predictions &#x3D; list(p[&quot;predictions&quot;] for p in itertools.islice(y, 6))
print(&quot;Predictions: &amp;#123;&amp;#125;&quot;.format(str(predictions)))
</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#-1"><span class="nav-number">3.</span> <span class="nav-text">1
predictions &#x3D; list(p[&quot;predictions&quot;][0] for p in itertools.islice(y, 6))
</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TensorBoard-Visualizing-Learning"><span class="nav-number">4.</span> <span class="nav-text">TensorBoard: Visualizing Learning</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="龙"
      src="/images/head/head_bigfan.png">
  <p class="site-author-name" itemprop="name">龙</p>
  <div class="site-description" itemprop="description">哇咔咔</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">91</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">32</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">龙</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
